{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 经典又兼具备趣味性的Kaggle案例[泰坦尼克号问题](https://www.kaggle.com/c/titanic)\n",
    "大家都熟悉的『Jack and Rose』的故事，豪华游艇倒了，大家都惊恐逃生，可是救生艇的数量有限，无法人人都有，副船长发话了『lady and kid first！』，所以是否获救其实并非随机，而是基于一些背景有rank先后的。<br>\n",
    "训练和测试数据是一些乘客的个人信息以及存活状况，要尝试根据它生成合适的模型并预测其他人的存活状况。<br>\n",
    "对，这是一个二分类问题，很多分类算法都可以解决。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=red>看看数据长什么样</font>**<br>\n",
    "还是用pandas加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这个ipython notebook主要是我解决Kaggle Titanic问题的思路和过程\n",
    "\n",
    "import pandas as pd #数据分析\n",
    "import numpy as np #科学计算\n",
    "from pandas import Series,DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_train = pd.read_csv(\"Train.csv\")\n",
    "data_train.columns\n",
    "#data_train[data_train.Cabin.notnull()]['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=red>我们看大概有以下这些字段</font>**<br>\n",
    "PassengerId => 乘客ID<br>\n",
    "Pclass => 乘客等级(1/2/3等舱位)<br>\n",
    "Name => 乘客姓名<br>\n",
    "Sex => 性别<br>\n",
    "Age => 年龄<br>\n",
    "SibSp => 堂兄弟/妹个数<br>\n",
    "Parch => 父母与小孩个数<br>\n",
    "Ticket => 船票信息<br>\n",
    "Fare => 票价<br>\n",
    "Cabin => 客舱<br>\n",
    "Embarked => 登船港口"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=red>我这么懒的人显然会让pandas自己先告诉我们一些信息<font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>上面的数据说啥了？它告诉我们，训练数据中总共有891名乘客，但是很不幸，我们有些属性的数据不全，比如说：<font><br>\n",
    "\n",
    "* <font color=red>Age（年龄）属性只有714名乘客有记录<font>\n",
    "* <font color=red>Cabin（客舱）更是只有204名乘客是已知的<font>\n",
    "\n",
    "<font color=red>似乎信息略少啊，想再瞄一眼具体数据数值情况呢？恩，我们用下列的方法，得到数值型数据的一些分布(因为有些属性，比如姓名，是文本型；而另外一些属性，比如登船港口，是类目型。这些我们用下面的函数是看不到的)<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>mean字段告诉我们，大概0.383838的人最后获救了，2/3等舱的人数比1等舱要多，平均乘客年龄大概是29.7岁(计算这个时候会略掉无记录的)等等…<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=red>『对数据的认识太重要了！』<font>\n",
    "* <font color=red>『对数据的认识太重要了！』<font>\n",
    "* <font color=red>『对数据的认识太重要了！』<font>\n",
    "\n",
    "<font color=red>口号喊完了，上面的简单描述信息并没有什么卵用啊，咱们得再细一点分析下数据啊。<font><br>\n",
    "<font color=red>看看**每个/多个 属性和最后的Survived**之间有着什么样的关系<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tong.xing/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 8722 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/tong.xing/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 8722 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "fig.set(alpha=0.2)  # 设定图表颜色alpha参数\n",
    "\n",
    "plt.subplot2grid((2,3),(0,0))             # 在一张大图里分列几个小图\n",
    "data_train.Survived.value_counts().plot(kind='bar')# plots a bar graph of those who surived vs those who did not. \n",
    "plt.title(u\"获救情况 (1为获救)\") # puts a title on our graph\n",
    "plt.ylabel(u\"人数\")  \n",
    "\n",
    "plt.subplot2grid((2,3),(0,1))\n",
    "data_train.Pclass.value_counts().plot(kind=\"bar\")\n",
    "plt.ylabel(u\"人数\")\n",
    "plt.title(u\"乘客等级分布\")\n",
    "\n",
    "plt.subplot2grid((2,3),(0,2))\n",
    "plt.scatter(data_train.Survived, data_train.Age)\n",
    "plt.ylabel(u\"年龄\")                         # sets the y axis lable\n",
    "plt.grid(b=True, which='major', axis='y') # formats the grid line style of our graphs\n",
    "plt.title(u\"按年龄看获救分布 (1为获救)\")\n",
    "\n",
    "\n",
    "plt.subplot2grid((2,3),(1,0), colspan=2)\n",
    "data_train.Age[data_train.Pclass == 1].plot(kind='kde')   # plots a kernel desnsity estimate of the subset of the 1st class passanges's age\n",
    "data_train.Age[data_train.Pclass == 2].plot(kind='kde')\n",
    "data_train.Age[data_train.Pclass == 3].plot(kind='kde')\n",
    "plt.xlabel(u\"年龄\")# plots an axis lable\n",
    "plt.ylabel(u\"密度\") \n",
    "plt.title(u\"各等级的乘客年龄分布\")\n",
    "plt.legend((u'头等舱', u'2等舱',u'3等舱'),loc='best') # sets our legend for our graph.\n",
    "\n",
    "\n",
    "plt.subplot2grid((2,3),(1,2))\n",
    "data_train.Embarked.value_counts().plot(kind='bar')\n",
    "plt.title(u\"各登船口岸上船人数\")\n",
    "plt.ylabel(u\"人数\")  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "于是得到了像下面这样一张图：<br>\n",
    "![](http://7xo0y8.com1.z0.glb.clouddn.com/2_titanic/8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>bingo，图还是比数字好看多了。所以我们在图上可以看出来:<font><br>\n",
    "* <font color=red>被救的人300多点，不到半数；<font><br>\n",
    "* <font color=red>3等舱乘客灰常多；遇难和获救的人年龄似乎跨度都很广；<font><br>\n",
    "* <font color=red>3个不同的舱年龄总体趋势似乎也一致，2/3等舱乘客20岁多点的人最多，1等舱40岁左右的最多(→_→似乎符合财富和年龄的分配哈，咳咳，别理我，我瞎扯的)；<font><br>\n",
    "* <font color=red>登船港口人数按照S、C、Q递减，而且S远多于另外俩港口。<font><br><br>\n",
    "\n",
    "<font color=red>这个时候我们可能会有一些想法了：<font><br><br>\n",
    "\n",
    "1. <font color=red>不同舱位/乘客等级可能和财富/地位有关系，最后获救概率可能会不一样<font><br>\n",
    "2. <font color=red>年龄对获救概率也一定是有影响的，毕竟前面说了，副船长还说『小孩和女士先走』呢<font><br>\n",
    "3. <font color=red>和登船港口是不是有关系呢？也许登船港口不同，人的出身地位不同？<font><br>\n",
    "\n",
    "<font color=red>口说无凭，空想无益。老老实实再来统计统计，看看这些属性值的统计分布吧。<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#看看各乘客等级的获救情况\n",
    "fig = plt.figure()\n",
    "fig.set(alpha=0.2)  # 设定图表颜色alpha参数\n",
    "\n",
    "Survived_0 = data_train.Pclass[data_train.Survived == 0].value_counts()\n",
    "Survived_1 = data_train.Pclass[data_train.Survived == 1].value_counts()\n",
    "df=pd.DataFrame({u'获救':Survived_1, u'未获救':Survived_0})\n",
    "df.plot(kind='bar', stacked=True)\n",
    "plt.title(u\"各乘客等级的获救情况\")\n",
    "plt.xlabel(u\"乘客等级\") \n",
    "plt.ylabel(u\"人数\") \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>得到这个图：<font><br>\n",
    "![](http://7xo0y8.com1.z0.glb.clouddn.com/2_titanic/9.png?imageView/2/w/450/q/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>啧啧，果然，钱和地位对舱位有影响，进而对获救的可能性也有影响啊←_← <font><br>\n",
    "<font color=red>咳咳，跑题了，我想说的是，明显等级为1的乘客，获救的概率高很多。恩，这个一定是影响最后获救结果的一个特征。<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#看看各登录港口的获救情况\n",
    "fig = plt.figure()\n",
    "fig.set(alpha=0.2)  # 设定图表颜色alpha参数\n",
    "\n",
    "Survived_0 = data_train.Embarked[data_train.Survived == 0].value_counts()\n",
    "Survived_1 = data_train.Embarked[data_train.Survived == 1].value_counts()\n",
    "df=pd.DataFrame({u'获救':Survived_1, u'未获救':Survived_0})\n",
    "df.plot(kind='bar', stacked=True)\n",
    "plt.title(u\"各登录港口乘客的获救情况\")\n",
    "plt.xlabel(u\"登录港口\") \n",
    "plt.ylabel(u\"人数\") \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://7xo0y8.com1.z0.glb.clouddn.com/2_titanic/Embarked.png?imageView/2/w/500/q/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>并没有看出什么...<font><br>\n",
    "\n",
    "<font color=red>那个，看看性别好了<font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#看看各性别的获救情况\n",
    "fig = plt.figure()\n",
    "fig.set(alpha=0.2)  # 设定图表颜色alpha参数\n",
    "\n",
    "Survived_m = data_train.Survived[data_train.Sex == 'male'].value_counts()\n",
    "Survived_f = data_train.Survived[data_train.Sex == 'female'].value_counts()\n",
    "df=pd.DataFrame({u'男性':Survived_m, u'女性':Survived_f})\n",
    "df.plot(kind='bar', stacked=True)\n",
    "plt.title(u\"按性别看获救情况\")\n",
    "plt.xlabel(u\"性别\") \n",
    "plt.ylabel(u\"人数\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://7xo0y8.com1.z0.glb.clouddn.com/2_titanic/10.png?imageView/2/w/450/q/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>歪果盆友果然很尊重lady，lady first践行得不错。性别无疑也要作为重要特征加入最后的模型之中。<font><br>\n",
    "\n",
    "<font color=red>再来个详细版的好了<font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#然后我们再来看看各种舱级别情况下各性别的获救情况\n",
    "fig=plt.figure()\n",
    "fig.set(alpha=0.65) # 设置图像透明度，无所谓\n",
    "plt.title(u\"根据舱等级和性别的获救情况\")\n",
    "\n",
    "ax1=fig.add_subplot(141)\n",
    "data_train.Survived[data_train.Sex == 'female'][data_train.Pclass != 3].value_counts().plot(kind='bar', label=\"female highclass\", color='#FA2479')\n",
    "ax1.set_xticklabels([u\"获救\", u\"未获救\"], rotation=0)\n",
    "ax1.legend([u\"女性/高级舱\"], loc='best')\n",
    "\n",
    "ax2=fig.add_subplot(142, sharey=ax1)\n",
    "data_train.Survived[data_train.Sex == 'female'][data_train.Pclass == 3].value_counts().plot(kind='bar', label='female, low class', color='pink')\n",
    "ax2.set_xticklabels([u\"未获救\", u\"获救\"], rotation=0)\n",
    "plt.legend([u\"女性/低级舱\"], loc='best')\n",
    "\n",
    "ax3=fig.add_subplot(143, sharey=ax1)\n",
    "data_train.Survived[data_train.Sex == 'male'][data_train.Pclass != 3].value_counts().plot(kind='bar', label='male, high class',color='lightblue')\n",
    "ax3.set_xticklabels([u\"未获救\", u\"获救\"], rotation=0)\n",
    "plt.legend([u\"男性/高级舱\"], loc='best')\n",
    "\n",
    "ax4=fig.add_subplot(144, sharey=ax1)\n",
    "data_train.Survived[data_train.Sex == 'male'][data_train.Pclass == 3].value_counts().plot(kind='bar', label='male low class', color='steelblue')\n",
    "ax4.set_xticklabels([u\"未获救\", u\"获救\"], rotation=0)\n",
    "plt.legend([u\"男性/低级舱\"], loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://7xo0y8.com1.z0.glb.clouddn.com/2_titanic/11.png?imageView/2/w/700/q/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>那堂兄弟和父母呢？<font>\n",
    "<font color=red>大家族会有优势么？<font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PassengerId\n",
       "SibSp Survived             \n",
       "0     0                 398\n",
       "      1                 210\n",
       "1     0                  97\n",
       "      1                 112\n",
       "2     0                  15\n",
       "      1                  13\n",
       "3     0                  12\n",
       "      1                   4\n",
       "4     0                  15\n",
       "      1                   3\n",
       "5     0                   5\n",
       "8     0                   7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = data_train.groupby(['SibSp','Survived'])\n",
    "df = pd.DataFrame(g.count()['PassengerId'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PassengerId\n",
       "Parch Survived             \n",
       "0     0                 445\n",
       "      1                 233\n",
       "1     0                  53\n",
       "      1                  65\n",
       "2     0                  40\n",
       "      1                  40\n",
       "3     0                   2\n",
       "      1                   3\n",
       "4     0                   4\n",
       "5     0                   4\n",
       "      1                   1\n",
       "6     0                   1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = data_train.groupby(['Parch','Survived'])\n",
    "df = pd.DataFrame(g.count()['PassengerId'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>好吧，没看出特别特别明显的规律(为自己的智商感到捉急…)，先作为备选特征，放一放。<font><br>\n",
    "<font color=red>看看船票好了<font><br>\n",
    "<font color=red>ticket是船票编号，应该是unique的，和最后的结果没有太大的关系，不纳入考虑的特征范畴<font><br>\n",
    "<font color=red>cabin只有204个乘客有值，我们先看看它的一个分布<font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B96 B98        4\n",
       "G6             4\n",
       "C23 C25 C27    4\n",
       "C22 C26        3\n",
       "F33            3\n",
       "              ..\n",
       "B71            1\n",
       "E34            1\n",
       "E77            1\n",
       "C148           1\n",
       "B41            1\n",
       "Name: Cabin, Length: 147, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ticket是船票编号，应该是unique的，和最后的结果没有太大的关系，不纳入考虑的特征范畴\n",
    "#cabin只有204个乘客有值，我们先看看它的一个分布\n",
    "data_train.Cabin.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>这三三两两的…如此不集中…我们猜一下，也许，前面的ABCDE是指的甲板位置、然后编号是房间号？…好吧，我瞎说的，别当真…<font><br>\n",
    "<font color=red>关键是Cabin这鬼属性，应该算作类目型的，本来缺失值就多，还如此不集中，注定是个棘手货…第一感觉，这玩意儿如果直接按照类目特征处理的话，太散了，估计每个因子化后的特征都拿不到什么权重。加上有那么多缺失值，要不我们先把Cabin缺失与否作为条件(虽然这部分信息缺失可能并非未登记，maybe只是丢失了而已，所以这样做未必妥当)，先在有无Cabin信息这个粗粒度上看看Survived的情况好了。<font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cabin的值计数太分散了，绝大多数Cabin值只出现一次。感觉上作为类目，加入特征未必会有效\n",
    "#那我们一起看看这个值的有无，对于survival的分布状况，影响如何吧\n",
    "fig = plt.figure()\n",
    "fig.set(alpha=0.2)  # 设定图表颜色alpha参数\n",
    "\n",
    "Survived_cabin = data_train.Survived[pd.notnull(data_train.Cabin)].value_counts()\n",
    "Survived_nocabin = data_train.Survived[pd.isnull(data_train.Cabin)].value_counts()\n",
    "df=pd.DataFrame({u'有':Survived_cabin, u'无':Survived_nocabin}).transpose()\n",
    "df.plot(kind='bar', stacked=True)\n",
    "plt.title(u\"按Cabin有无看获救情况\")\n",
    "plt.xlabel(u\"Cabin有无\") \n",
    "plt.ylabel(u\"人数\")\n",
    "plt.show()\n",
    "\n",
    "#似乎有cabin记录的乘客survival比例稍高，那先试试把这个值分为两类，有cabin值/无cabin值，一会儿加到类别特征好了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://7xo0y8.com1.z0.glb.clouddn.com/2_titanic/15.png?imageView/2/w/400/q/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>有Cabin记录的似乎获救概率稍高一些，先这么着放一放吧。<font><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>先从最突出的数据属性开始吧，对，Cabin和Age，有丢失数据实在是对下一步工作影响太大。<font><br>\n",
    "\n",
    "<font color=red>先说Cabin，暂时我们就按照刚才说的，按Cabin有无数据，将这个属性处理成Yes和No两种类型吧。<font><br>\n",
    "\n",
    "<font color=red>再说Age：<font><br>\n",
    "\n",
    "<font color=red>通常遇到缺值的情况，我们会有几种常见的处理方式<font><br>\n",
    "\n",
    "1. <font color=red>如果缺值的样本占总数比例极高，我们可能就直接舍弃了，作为特征加入的话，可能反倒带入noise，影响最后的结果了<font><br>\n",
    "2. <font color=red>如果缺值的样本适中，而该属性非连续值特征属性(比如说类目属性)，那就把NaN作为一个新类别，加到类别特征中<font><br>\n",
    "3. <font color=red>如果缺值的样本适中，而该属性为连续值特征属性，有时候我们会考虑给定一个step(比如这里的age，我们可以考虑每隔2/3岁为一个步长)，然后把它离散化，之后把NaN作为一个type加到属性类目中。<font><br>\n",
    "4. <font color=red>有些情况下，缺失的值个数并不是特别多，那我们也可以试着根据已有的值，拟合一下数据，补充上。<font><br>\n",
    "<font color=red>本例中，后两种处理方式应该都是可行的，我们先试试拟合补全吧(虽然说没有特别多的背景可供我们拟合，这不一定是一个多么好的选择)<font><br>\n",
    "\n",
    "<font color=red>我们这里用scikit-learn中的RandomForest来拟合一下缺失的年龄数据<font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>No</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Yes</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>No</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>No</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>16.185117</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>No</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>No</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex        Age  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.000000   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.000000   \n",
       "2                               Heikkinen, Miss. Laina  female  26.000000   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.000000   \n",
       "4                             Allen, Mr. William Henry    male  35.000000   \n",
       "..                                                 ...     ...        ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.000000   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.000000   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female  16.185117   \n",
       "889                              Behr, Mr. Karl Howell    male  26.000000   \n",
       "890                                Dooley, Mr. Patrick    male  32.000000   \n",
       "\n",
       "     SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0        1      0         A/5 21171   7.2500    No        S  \n",
       "1        1      0          PC 17599  71.2833   Yes        C  \n",
       "2        0      0  STON/O2. 3101282   7.9250    No        S  \n",
       "3        1      0            113803  53.1000   Yes        S  \n",
       "4        0      0            373450   8.0500    No        S  \n",
       "..     ...    ...               ...      ...   ...      ...  \n",
       "886      0      0            211536  13.0000    No        S  \n",
       "887      0      0            112053  30.0000   Yes        S  \n",
       "888      1      2        W./C. 6607  23.4500    No        S  \n",
       "889      0      0            111369  30.0000   Yes        C  \n",
       "890      0      0            370376   7.7500    No        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    " \n",
    "### 使用 RandomForestClassifier 填补缺失的年龄属性\n",
    "def set_missing_ages(df):\n",
    "    \n",
    "    # 把已有的数值型特征取出来丢进Random Forest Regressor中\n",
    "    age_df = df[['Age','Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "\n",
    "    # 乘客分成已知年龄和未知年龄两部分\n",
    "    known_age = age_df[age_df.Age.notnull()].values\n",
    "    unknown_age = age_df[age_df.Age.isnull()].values\n",
    "\n",
    "    # y即目标年龄\n",
    "    y = known_age[:, 0]\n",
    "\n",
    "    # X即特征属性值\n",
    "    X = known_age[:, 1:]\n",
    "\n",
    "    # fit到RandomForestRegressor之中\n",
    "    rfr = RandomForestRegressor(random_state=0, n_estimators=2000, n_jobs=-1)\n",
    "    rfr.fit(X, y)\n",
    "    \n",
    "    # 用得到的模型进行未知年龄结果预测\n",
    "    predictedAges = rfr.predict(unknown_age[:, 1::])\n",
    "    \n",
    "    # 用得到的预测结果填补原缺失数据\n",
    "    df.loc[ (df.Age.isnull()), 'Age' ] = predictedAges \n",
    "    \n",
    "    return df, rfr\n",
    "\n",
    "def set_Cabin_type(df):\n",
    "    df.loc[ (df.Cabin.notnull()), 'Cabin' ] = \"Yes\"\n",
    "    df.loc[ (df.Cabin.isnull()), 'Cabin' ] = \"No\"\n",
    "    return df\n",
    "\n",
    "data_train, rfr = set_missing_ages(data_train)\n",
    "data_train = set_Cabin_type(data_train)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>因为逻辑回归建模时，需要输入的特征都是数值型特征，我们通常会先对类目型的特征因子化/one-hot编码。 <font><br>\n",
    "<font color=red>什么叫做因子化/one-hot编码？举个例子：<font><br>\n",
    "\n",
    "<font color=red>以Embarked为例，原本一个属性维度，因为其取值可以是[‘S’,’C’,’Q‘]，而将其平展开为’Embarked_C’,’Embarked_S’, ‘Embarked_Q’三个属性<font><br>\n",
    "\n",
    "* <font color=red>原本Embarked取值为S的，在此处的”Embarked_S”下取值为1，在’Embarked_C’, ‘Embarked_Q’下取值为0<font><br>\n",
    "* <font color=red>原本Embarked取值为C的，在此处的”Embarked_C”下取值为1，在’Embarked_S’, ‘Embarked_Q’下取值为0<font><br>\n",
    "* <font color=red>原本Embarked取值为Q的，在此处的”Embarked_Q”下取值为1，在’Embarked_C’, ‘Embarked_S’下取值为0<font><br>\n",
    "\n",
    "<font color=red>我们使用pandas的”get_dummies”来完成这个工作，并拼接在原来的”data_train”之上，如下所示。<font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin_No</th>\n",
       "      <th>Cabin_Yes</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>16.185117</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived        Age  SibSp  Parch     Fare  Cabin_No  \\\n",
       "0              1         0  22.000000      1      0   7.2500         1   \n",
       "1              2         1  38.000000      1      0  71.2833         0   \n",
       "2              3         1  26.000000      0      0   7.9250         1   \n",
       "3              4         1  35.000000      1      0  53.1000         0   \n",
       "4              5         0  35.000000      0      0   8.0500         1   \n",
       "..           ...       ...        ...    ...    ...      ...       ...   \n",
       "886          887         0  27.000000      0      0  13.0000         1   \n",
       "887          888         1  19.000000      0      0  30.0000         0   \n",
       "888          889         0  16.185117      1      2  23.4500         1   \n",
       "889          890         1  26.000000      0      0  30.0000         0   \n",
       "890          891         0  32.000000      0      0   7.7500         1   \n",
       "\n",
       "     Cabin_Yes  Embarked_C  Embarked_Q  Embarked_S  Sex_female  Sex_male  \\\n",
       "0            0           0           0           1           0         1   \n",
       "1            1           1           0           0           1         0   \n",
       "2            0           0           0           1           1         0   \n",
       "3            1           0           0           1           1         0   \n",
       "4            0           0           0           1           0         1   \n",
       "..         ...         ...         ...         ...         ...       ...   \n",
       "886          0           0           0           1           0         1   \n",
       "887          1           0           0           1           1         0   \n",
       "888          0           0           0           1           1         0   \n",
       "889          1           1           0           0           0         1   \n",
       "890          0           0           1           0           0         1   \n",
       "\n",
       "     Pclass_1  Pclass_2  Pclass_3  \n",
       "0           0         0         1  \n",
       "1           1         0         0  \n",
       "2           0         0         1  \n",
       "3           1         0         0  \n",
       "4           0         0         1  \n",
       "..        ...       ...       ...  \n",
       "886         0         1         0  \n",
       "887         1         0         0  \n",
       "888         0         0         1  \n",
       "889         1         0         0  \n",
       "890         0         0         1  \n",
       "\n",
       "[891 rows x 16 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 因为逻辑回归建模时，需要输入的特征都是数值型特征\n",
    "# 我们先对类目型的特征离散/因子化\n",
    "# 以Cabin为例，原本一个属性维度，因为其取值可以是['yes','no']，而将其平展开为'Cabin_yes','Cabin_no'两个属性\n",
    "# 原本Cabin取值为yes的，在此处的'Cabin_yes'下取值为1，在'Cabin_no'下取值为0\n",
    "# 原本Cabin取值为no的，在此处的'Cabin_yes'下取值为0，在'Cabin_no'下取值为1\n",
    "# 我们使用pandas的get_dummies来完成这个工作，并拼接在原来的data_train之上，如下所示\n",
    "dummies_Cabin = pd.get_dummies(data_train['Cabin'], prefix= 'Cabin')\n",
    "\n",
    "dummies_Embarked = pd.get_dummies(data_train['Embarked'], prefix= 'Embarked')\n",
    "\n",
    "dummies_Sex = pd.get_dummies(data_train['Sex'], prefix= 'Sex')\n",
    "\n",
    "dummies_Pclass = pd.get_dummies(data_train['Pclass'], prefix= 'Pclass')\n",
    "\n",
    "df = pd.concat([data_train, dummies_Cabin, dummies_Embarked, dummies_Sex, dummies_Pclass], axis=1)\n",
    "df.drop(['Pclass', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>我们还得做一些处理，仔细看看Age和Fare两个属性，乘客的数值幅度变化，也忒大了吧！！如果大家了解逻辑回归与梯度下降的话，会知道，各属性值之间scale差距太大，将对收敛速度造成几万点伤害值！甚至不收敛！ (╬▔皿▔)…所以我们先用scikit-learn里面的preprocessing模块对这俩货做一个scaling，所谓scaling，其实就是将一些变化幅度较大的特征化到[-1,1]之内。<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = df['Age'].values\n",
    "df_age = df_age.reshape(-1, 1)\n",
    "\n",
    "df_fare = df['Fare'].values\n",
    "df_fare = df_fare.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_scale_param = scaler.fit(df_age)\n",
    "fare_scale_param = scaler.fit(df_fare)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin_No</th>\n",
       "      <th>Cabin_Yes</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Age_scaled</th>\n",
       "      <th>Fare_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.561377</td>\n",
       "      <td>-0.502445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.613173</td>\n",
       "      <td>0.786845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.267740</td>\n",
       "      <td>-0.488854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392945</td>\n",
       "      <td>0.420730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392945</td>\n",
       "      <td>-0.486337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.194330</td>\n",
       "      <td>-0.386671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.781606</td>\n",
       "      <td>-0.044381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>16.185117</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.988244</td>\n",
       "      <td>-0.176263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.267740</td>\n",
       "      <td>-0.044381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.172717</td>\n",
       "      <td>-0.492378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived        Age  SibSp  Parch     Fare  Cabin_No  \\\n",
       "0              1         0  22.000000      1      0   7.2500         1   \n",
       "1              2         1  38.000000      1      0  71.2833         0   \n",
       "2              3         1  26.000000      0      0   7.9250         1   \n",
       "3              4         1  35.000000      1      0  53.1000         0   \n",
       "4              5         0  35.000000      0      0   8.0500         1   \n",
       "..           ...       ...        ...    ...    ...      ...       ...   \n",
       "886          887         0  27.000000      0      0  13.0000         1   \n",
       "887          888         1  19.000000      0      0  30.0000         0   \n",
       "888          889         0  16.185117      1      2  23.4500         1   \n",
       "889          890         1  26.000000      0      0  30.0000         0   \n",
       "890          891         0  32.000000      0      0   7.7500         1   \n",
       "\n",
       "     Cabin_Yes  Embarked_C  Embarked_Q  Embarked_S  Sex_female  Sex_male  \\\n",
       "0            0           0           0           1           0         1   \n",
       "1            1           1           0           0           1         0   \n",
       "2            0           0           0           1           1         0   \n",
       "3            1           0           0           1           1         0   \n",
       "4            0           0           0           1           0         1   \n",
       "..         ...         ...         ...         ...         ...       ...   \n",
       "886          0           0           0           1           0         1   \n",
       "887          1           0           0           1           1         0   \n",
       "888          0           0           0           1           1         0   \n",
       "889          1           1           0           0           0         1   \n",
       "890          0           0           1           0           0         1   \n",
       "\n",
       "     Pclass_1  Pclass_2  Pclass_3  Age_scaled  Fare_scaled  \n",
       "0           0         0         1   -0.561377    -0.502445  \n",
       "1           1         0         0    0.613173     0.786845  \n",
       "2           0         0         1   -0.267740    -0.488854  \n",
       "3           1         0         0    0.392945     0.420730  \n",
       "4           0         0         1    0.392945    -0.486337  \n",
       "..        ...       ...       ...         ...          ...  \n",
       "886         0         1         0   -0.194330    -0.386671  \n",
       "887         1         0         0   -0.781606    -0.044381  \n",
       "888         0         0         1   -0.988244    -0.176263  \n",
       "889         1         0         0   -0.267740    -0.044381  \n",
       "890         0         0         1    0.172717    -0.492378  \n",
       "\n",
       "[891 rows x 18 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 接下来我们要接着做一些数据预处理的工作，比如scaling，将一些变化幅度较大的特征化到[-1,1]之内\n",
    "# 这样可以加速logistic regression的收敛\n",
    "import sklearn.preprocessing as preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# preprocessing.StandardScaler().fit(X)\n",
    "# age_scale_param = scaler.fit(df_age)\n",
    "df['Age_scaled'] = scaler.fit_transform(df_age, age_scale_param)\n",
    "# fare_scale_param = scaler.fit(df['Fare'].values)\n",
    "df['Fare_scaled'] = scaler.fit_transform(df_fare, fare_scale_param)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>我们把需要的feature字段取出来，转成numpy格式，使用scikit-learn中的LogisticRegression建模。<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(tol=1e-06)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们把需要的feature字段取出来，转成numpy格式，使用scikit-learn中的LogisticRegression建模\n",
    "from sklearn import linear_model\n",
    "\n",
    "train_df = df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\n",
    "train_np = train_df.values\n",
    "\n",
    "# y即Survival结果\n",
    "y = train_np[:, 0]\n",
    "\n",
    "# X即特征属性值\n",
    "X = train_np[:, 1:]\n",
    "\n",
    "# fit到RandomForestRegressor之中\n",
    "clf = linear_model.LogisticRegression(C=1.0, penalty='l2', tol=1e-6)\n",
    "clf.fit(X, y)\n",
    "    \n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来咱们对训练集和测试集做一样的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin_No</th>\n",
       "      <th>Cabin_Yes</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Age_scaled</th>\n",
       "      <th>Fare_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.307526</td>\n",
       "      <td>-0.496637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.256242</td>\n",
       "      <td>-0.511497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.394702</td>\n",
       "      <td>-0.463335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.261704</td>\n",
       "      <td>-0.481704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.641190</td>\n",
       "      <td>-0.416740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>30.705727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019551</td>\n",
       "      <td>-0.492680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.649064</td>\n",
       "      <td>1.314641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611115</td>\n",
       "      <td>-0.507017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>30.705727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019551</td>\n",
       "      <td>-0.492680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>25.755877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.356130</td>\n",
       "      <td>-0.236263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId        Age  SibSp  Parch      Fare  Cabin_No  Cabin_Yes  \\\n",
       "0            892  34.500000      0      0    7.8292         1          0   \n",
       "1            893  47.000000      1      0    7.0000         1          0   \n",
       "2            894  62.000000      0      0    9.6875         1          0   \n",
       "3            895  27.000000      0      0    8.6625         1          0   \n",
       "4            896  22.000000      1      1   12.2875         1          0   \n",
       "..           ...        ...    ...    ...       ...       ...        ...   \n",
       "413         1305  30.705727      0      0    8.0500         1          0   \n",
       "414         1306  39.000000      0      0  108.9000         0          1   \n",
       "415         1307  38.500000      0      0    7.2500         1          0   \n",
       "416         1308  30.705727      0      0    8.0500         1          0   \n",
       "417         1309  25.755877      1      1   22.3583         1          0   \n",
       "\n",
       "     Embarked_C  Embarked_Q  Embarked_S  Sex_female  Sex_male  Pclass_1  \\\n",
       "0             0           1           0           0         1         0   \n",
       "1             0           0           1           1         0         0   \n",
       "2             0           1           0           0         1         0   \n",
       "3             0           0           1           0         1         0   \n",
       "4             0           0           1           1         0         0   \n",
       "..          ...         ...         ...         ...       ...       ...   \n",
       "413           0           0           1           0         1         0   \n",
       "414           1           0           0           1         0         1   \n",
       "415           0           0           1           0         1         0   \n",
       "416           0           0           1           0         1         0   \n",
       "417           1           0           0           0         1         0   \n",
       "\n",
       "     Pclass_2  Pclass_3  Age_scaled  Fare_scaled  \n",
       "0           0         1    0.307526    -0.496637  \n",
       "1           0         1    1.256242    -0.511497  \n",
       "2           1         0    2.394702    -0.463335  \n",
       "3           0         1   -0.261704    -0.481704  \n",
       "4           0         1   -0.641190    -0.416740  \n",
       "..        ...       ...         ...          ...  \n",
       "413         0         1    0.019551    -0.492680  \n",
       "414         0         0    0.649064     1.314641  \n",
       "415         0         1    0.611115    -0.507017  \n",
       "416         0         1    0.019551    -0.492680  \n",
       "417         0         1   -0.356130    -0.236263  \n",
       "\n",
       "[418 rows x 17 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(\"test.csv\")\n",
    "data_test.loc[ (data_test.Fare.isnull()), 'Fare' ] = 0\n",
    "# 接着我们对test_data做和train_data中一致的特征变换\n",
    "# 首先用同样的RandomForestRegressor模型填上丢失的年龄\n",
    "tmp_df = data_test[['Age','Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "null_age = tmp_df[data_test.Age.isnull()].values\n",
    "# 根据特征属性X预测年龄并补上\n",
    "X = null_age[:, 1:]\n",
    "predictedAges = rfr.predict(X)\n",
    "data_test.loc[ (data_test.Age.isnull()), 'Age' ] = predictedAges\n",
    "\n",
    "data_test = set_Cabin_type(data_test)\n",
    "dummies_Cabin = pd.get_dummies(data_test['Cabin'], prefix= 'Cabin')\n",
    "dummies_Embarked = pd.get_dummies(data_test['Embarked'], prefix= 'Embarked')\n",
    "dummies_Sex = pd.get_dummies(data_test['Sex'], prefix= 'Sex')\n",
    "dummies_Pclass = pd.get_dummies(data_test['Pclass'], prefix= 'Pclass')\n",
    "\n",
    "\n",
    "df_test = pd.concat([data_test, dummies_Cabin, dummies_Embarked, dummies_Sex, dummies_Pclass], axis=1)\n",
    "df_test.drop(['Pclass', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)\n",
    "\n",
    "df_test['Age_scaled'] = scaler.fit_transform(df_test_age, age_scale_param)\n",
    "df_test['Fare_scaled'] = scaler.fit_transform(df_test_fare, fare_scale_param)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_age = df_test['Age'].values.reshape(-1, 1)\n",
    "df_test_fare = df_test['Fare'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_test.filter(regex='Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\n",
    "predictions = clf.predict(test)\n",
    "result = pd.DataFrame({'PassengerId':data_test['PassengerId'].values, 'Survived':predictions.astype(np.int32)})\n",
    "result.to_csv(\"logistic_regression_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"logistic_regression_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=red>0.76555，恩，结果还不错。毕竟，这只是我们简单分析过后出的一个baseline系统嘛</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要判定一下当前模型所处状态(欠拟合or过拟合)\n",
    "\n",
    "<font color=red>有一个很可能发生的问题是，我们不断地做feature engineering，产生的特征越来越多，用这些特征去训练模型，会对我们的训练集拟合得越来越好，同时也可能在逐步丧失泛化能力，从而在待预测的数据上，表现不佳，也就是发生过拟合问题。<font><br>\n",
    "\n",
    "<font color=red>从另一个角度上说，如果模型在待预测的数据上表现不佳，除掉上面说的过拟合问题，也有可能是欠拟合问题，也就是说在训练集上，其实拟合的也不是那么好。<font><br>\n",
    "\n",
    "<font color=red>额，这个欠拟合和过拟合怎么解释呢。这么说吧：<font><br>\n",
    "\n",
    "1. <font color=red>过拟合就像是你班那个学数学比较刻板的同学，老师讲过的题目，一字不漏全记下来了，于是老师再出一样的题目，分分钟精确出结果。but数学考试，因为总是碰到新题目，所以成绩不咋地。<font>\n",
    "2. <font color=red>欠拟合就像是，咳咳，和博主level差不多的差生。连老师讲的练习题也记不住，于是连老师出一样题目复习的周测都做不好，考试更是可想而知了。<font>\n",
    "\n",
    "<font color=red>而在机器学习的问题上，对于过拟合和欠拟合两种情形。我们优化的方式是不同的。<font><br>\n",
    "\n",
    "<font color=red>对过拟合而言，通常以下策略对结果优化是有用的：<font><br>\n",
    "\n",
    "* <font color=red>做一下feature selection，挑出较好的feature的subset来做training\n",
    "* <font color=red>提供更多的数据，从而弥补原始数据的bias问题，学习到的model也会更准确\n",
    "\n",
    "<font color=red>而对于欠拟合而言，我们通常需要更多的feature，更复杂的模型来提高准确度。<font><br>\n",
    "\n",
    "<font color=red>著名的learning curve可以帮我们判定我们的模型现在所处的状态。我们以样本数为横坐标，训练和交叉验证集上的错误率作为纵坐标，两种状态分别如下两张图所示：过拟合(overfitting/high variace)，欠拟合(underfitting/high bias)<font><br>\n",
    "\n",
    "![](http://7xo0y8.com1.z0.glb.clouddn.com/2_titanic/high_variance.png?imageView/2/w/400/q/100)\n",
    "![](http://7xo0y8.com1.z0.glb.clouddn.com/2_titanic/high_bias.png?imageView/2/w/400/q/100)\n",
    "\n",
    "<font color=red>著名的learning curve可以帮我们判定我们的模型现在所处的状态。我们以样本数为横坐标，训练和交叉验证集上的错误率作为纵坐标，两种状态分别如下两张图所示：过拟合(overfitting/high variace)，欠拟合(underfitting/high bias)<font><br>\n",
    "\n",
    "<font color=red>我们也可以把错误率替换成准确率(得分)，得到另一种形式的learning curve(sklearn 里面是这么做的)。<font><br>\n",
    "\n",
    "<font color=red>回到我们的问题，我们用scikit-learn里面的learning_curve来帮我们分辨我们模型的状态。举个例子，这里我们一起画一下我们最先得到的baseline model的learning curve。<font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.8958,  0.    ,  0.    ,  3.    ],\n",
       "       [31.6833,  0.    ,  0.    ,  1.    ],\n",
       "       [21.6792,  0.    ,  2.    ,  3.    ],\n",
       "       [23.45  ,  2.    ,  1.    ,  3.    ],\n",
       "       [ 8.05  ,  0.    ,  0.    ,  3.    ],\n",
       "       [56.4958,  0.    ,  0.    ,  3.    ],\n",
       "       [26.55  ,  0.    ,  0.    ,  1.    ],\n",
       "       [ 7.75  ,  0.    ,  0.    ,  3.    ],\n",
       "       [15.5792,  0.    ,  0.    ,  2.    ],\n",
       "       [16.1   ,  0.    ,  1.    ,  3.    ],\n",
       "       [21.    ,  0.    ,  0.    ,  2.    ],\n",
       "       [ 8.05  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.8958,  0.    ,  0.    ,  3.    ],\n",
       "       [10.7083,  0.    ,  0.    ,  2.    ],\n",
       "       [14.4542,  0.    ,  1.    ,  3.    ],\n",
       "       [ 7.75  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.775 ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 8.05  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.75  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.75  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 8.7125,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.7792,  0.    ,  0.    ,  3.    ],\n",
       "       [ 6.4375,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.75  ,  0.    ,  1.    ,  3.    ],\n",
       "       [ 7.75  ,  0.    ,  0.    ,  3.    ],\n",
       "       [23.25  ,  0.    ,  2.    ,  3.    ],\n",
       "       [25.4667,  4.    ,  0.    ,  3.    ],\n",
       "       [ 6.4375,  0.    ,  1.    ,  3.    ],\n",
       "       [51.8625,  0.    ,  0.    ,  1.    ],\n",
       "       [26.55  ,  0.    ,  0.    ,  1.    ],\n",
       "       [ 7.8958,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.7333,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.    ,  0.    ,  0.    ,  3.    ],\n",
       "       [27.7208,  0.    ,  0.    ,  1.    ],\n",
       "       [ 7.55  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.2292,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.75  ,  0.    ,  0.    ,  3.    ],\n",
       "       [69.55  ,  2.    ,  8.    ,  3.    ],\n",
       "       [26.    ,  0.    ,  0.    ,  1.    ],\n",
       "       [ 8.1125,  0.    ,  0.    ,  3.    ],\n",
       "       [15.5   ,  0.    ,  0.    ,  3.    ],\n",
       "       [25.7417,  0.    ,  0.    ,  1.    ],\n",
       "       [ 7.05  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.8792,  0.    ,  0.    ,  3.    ],\n",
       "       [ 8.05  ,  0.    ,  0.    ,  3.    ],\n",
       "       [15.2458,  2.    ,  0.    ,  3.    ],\n",
       "       [ 7.75  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.8792,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.8875,  0.    ,  0.    ,  3.    ],\n",
       "       [23.45  ,  2.    ,  1.    ,  3.    ],\n",
       "       [14.4542,  0.    ,  1.    ,  3.    ],\n",
       "       [ 7.55  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.75  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.8958,  0.    ,  0.    ,  3.    ],\n",
       "       [ 0.    ,  0.    ,  0.    ,  1.    ],\n",
       "       [ 7.55  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 8.05  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.75  ,  0.    ,  0.    ,  3.    ],\n",
       "       [15.5   ,  0.    ,  1.    ,  3.    ],\n",
       "       [ 7.225 ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.75  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.25  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.2292,  0.    ,  0.    ,  3.    ],\n",
       "       [ 8.05  ,  0.    ,  0.    ,  3.    ],\n",
       "       [39.6   ,  0.    ,  0.    ,  1.    ],\n",
       "       [ 7.2292,  0.    ,  0.    ,  3.    ],\n",
       "       [21.6792,  0.    ,  2.    ,  3.    ],\n",
       "       [15.0458,  0.    ,  0.    ,  2.    ],\n",
       "       [ 7.75  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.575 ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.225 ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.2292,  0.    ,  0.    ,  3.    ],\n",
       "       [69.55  ,  9.    ,  1.    ,  3.    ],\n",
       "       [14.5   ,  1.    ,  1.    ,  3.    ],\n",
       "       [ 7.8792,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.75  ,  0.    ,  0.    ,  3.    ],\n",
       "       [69.55  ,  9.    ,  1.    ,  3.    ],\n",
       "       [14.4583,  0.    ,  1.    ,  3.    ],\n",
       "       [ 7.75  ,  0.    ,  0.    ,  3.    ],\n",
       "       [14.5   ,  0.    ,  0.    ,  3.    ],\n",
       "       [12.875 ,  0.    ,  0.    ,  2.    ],\n",
       "       [ 7.7208,  0.    ,  0.    ,  3.    ],\n",
       "       [ 7.75  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 8.05  ,  0.    ,  0.    ,  3.    ],\n",
       "       [ 8.05  ,  0.    ,  0.    ,  3.    ],\n",
       "       [22.3583,  1.    ,  1.    ,  3.    ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [86, 891]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-6a1e9dce387c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmidpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"学习曲线\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-6a1e9dce387c>\u001b[0m in \u001b[0;36mplot_learning_curve\u001b[0;34m(estimator, title, X, y, ylim, cv, n_jobs, train_sizes, verbose, plot)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \"\"\"\n\u001b[1;32m     21\u001b[0m     train_sizes, train_scores, test_scores = learning_curve(\n\u001b[0;32m---> 22\u001b[0;31m         estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, verbose=verbose)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtrain_scores_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mlearning_curve\u001b[0;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         raise ValueError(\"An estimator must support the partial_fit interface \"\n\u001b[1;32m   1242\u001b[0m                          \"to exploit incremental learning\")\n\u001b[0;32m-> 1243\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \"\"\"\n\u001b[1;32m    291\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 256\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [86, 891]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.learning_curve import learning_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# 用sklearn的learning_curve得到training_score和cv_score，使用matplotlib画出learning curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=1, \n",
    "                        train_sizes=np.linspace(.05, 1., 20), verbose=0, plot=True):\n",
    "    \"\"\"\n",
    "    画出data在某模型上的learning curve.\n",
    "    参数解释\n",
    "    ----------\n",
    "    estimator : 你用的分类器。\n",
    "    title : 表格的标题。\n",
    "    X : 输入的feature，numpy类型\n",
    "    y : 输入的target vector\n",
    "    ylim : tuple格式的(ymin, ymax), 设定图像中纵坐标的最低点和最高点\n",
    "    cv : 做cross-validation的时候，数据分成的份数，其中一份作为cv集，其余n-1份作为training(默认为3份)\n",
    "    n_jobs : 并行的的任务数(默认1)\n",
    "    \"\"\"\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, verbose=verbose)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.title(title)\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.xlabel(u\"训练样本数\")  \n",
    "        plt.ylabel(u\"得分\")\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.grid()\n",
    "    \n",
    "        plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, \n",
    "                         alpha=0.1, color=\"b\")\n",
    "        plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, \n",
    "                         alpha=0.1, color=\"r\")\n",
    "        plt.plot(train_sizes, train_scores_mean, 'o-', color=\"b\", label=u\"训练集上得分\")\n",
    "        plt.plot(train_sizes, test_scores_mean, 'o-', color=\"r\", label=u\"交叉验证集上得分\")\n",
    "    \n",
    "        plt.legend(loc=\"best\")\n",
    "        \n",
    "        plt.draw()\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.show()\n",
    "    \n",
    "    midpoint = ((train_scores_mean[-1] + train_scores_std[-1]) + (test_scores_mean[-1] - test_scores_std[-1])) / 2\n",
    "    diff = (train_scores_mean[-1] + train_scores_std[-1]) - (test_scores_mean[-1] - test_scores_std[-1])\n",
    "    return midpoint, diff\n",
    "\n",
    "plot_learning_curve(clf, u\"学习曲线\", X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://7xo0y8.com1.z0.glb.clouddn.com/2_titanic/learning_curve.png?imageView/2/w/600/q/100)\n",
    "<font color=red>在实际数据上看，我们得到的learning curve没有理论推导的那么光滑哈，但是可以大致看出来，训练集和交叉验证集上的得分曲线走势还是符合预期的。<font><br>\n",
    "\n",
    "<font color=red>目前的曲线看来，我们的model并不处于overfitting的状态(overfitting的表现一般是训练集上得分高，而交叉验证集上要低很多，中间的gap比较大)。因此我们可以再做些feature engineering的工作，添加一些新产出的特征或者组合特征到模型中。<font><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>接下来，我们就该看看如何优化baseline系统了<br>\n",
    "我们还有些特征可以再挖掘挖掘<br><br>\n",
    "\n",
    "1. 比如说Name和Ticket两个属性被我们完整舍弃了(好吧，其实是一开始我们对于这种，每一条记录都是一个完全不同的值的属性，并没有很直接的处理方式)<br>\n",
    "2. 比如说，我们想想，年龄的拟合本身也未必是一件非常靠谱的事情<br>\n",
    "3. 另外，以我们的日常经验，小盆友和老人可能得到的照顾会多一些，这样看的话，年龄作为一个连续值，给一个固定的系数，似乎体现不出两头受照顾的实际情况，所以，说不定我们把年龄离散化，按区段分作类别属性会更合适一些<br>\n",
    "\n",
    "那怎么样才知道，哪些地方可以优化，哪些优化的方法是promising的呢？<br>\n",
    "是的<br><br>\n",
    "\n",
    "要做交叉验证(cross validation)!<br>\n",
    "要做交叉验证(cross validation)!<br>\n",
    "要做交叉验证(cross validation)!<br><br>\n",
    "\n",
    "重要的事情说3编！！！<br>\n",
    "因为test.csv里面并没有Survived这个字段(好吧，这是废话，这明明就是我们要预测的结果)，我们无法在这份数据上评定我们算法在该场景下的效果。。。<br>\n",
    "我们通常情况下，这么做cross validation：把train.csv分成两部分，一部分用于训练我们需要的模型，另外一部分数据上看我们预测算法的效果。<br>\n",
    "我们可以用scikit-learn的cross_validation来完成这个工作</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>在此之前，咱们可以看看现在得到的模型的系数，因为系数和它们最终的判定能力强弱是正相关的</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>[-0.3496926584356524]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parch</td>\n",
       "      <td>[-0.11594837829158244]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cabin_No</td>\n",
       "      <td>[-0.4668144866573548]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabin_Yes</td>\n",
       "      <td>[0.46673068010927]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>[0.09104690422200368]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>[0.08401916280137448]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>[-0.3498583736232787]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sex_female</td>\n",
       "      <td>[1.315782811474743]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>[-1.315866618022825]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>[0.6176491672036704]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>[0.2860850112583741]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>[-0.9038179850101292]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Age_scaled</td>\n",
       "      <td>[-0.5340503256368865]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fare_scaled</td>\n",
       "      <td>[0.09220750646676204]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        columns                    coef\n",
       "0         SibSp   [-0.3496926584356524]\n",
       "1         Parch  [-0.11594837829158244]\n",
       "2      Cabin_No   [-0.4668144866573548]\n",
       "3     Cabin_Yes      [0.46673068010927]\n",
       "4    Embarked_C   [0.09104690422200368]\n",
       "5    Embarked_Q   [0.08401916280137448]\n",
       "6    Embarked_S   [-0.3498583736232787]\n",
       "7    Sex_female     [1.315782811474743]\n",
       "8      Sex_male    [-1.315866618022825]\n",
       "9      Pclass_1    [0.6176491672036704]\n",
       "10     Pclass_2    [0.2860850112583741]\n",
       "11     Pclass_3   [-0.9038179850101292]\n",
       "12   Age_scaled   [-0.5340503256368865]\n",
       "13  Fare_scaled   [0.09220750646676204]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"columns\":list(train_df.columns)[1:], \"coef\":list(clf.coef_.T)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "上面的系数和最后的结果是一个正相关的关系<br>\n",
    "我们先看看那些权重绝对值非常大的feature，在我们的模型上：<br>\n",
    "\n",
    "* Sex属性，如果是female会极大提高最后获救的概率，而male会很大程度拉低这个概率。\n",
    "* Pclass属性，1等舱乘客最后获救的概率会上升，而乘客等级为3会极大地拉低这个概率。\n",
    "* 有Cabin值会很大程度拉升最后获救概率(这里似乎能看到了一点端倪，事实上从最上面的有无Cabin记录的Survived分布图上看出，即使有Cabin记录的乘客也有一部分遇难了，估计这个属性上我们挖掘还不够)\n",
    "* Age是一个负相关，意味着在我们的模型里，年龄越小，越有获救的优先权(还得回原数据看看这个是否合理）\n",
    "* 有一个登船港口S会很大程度拉低获救的概率，另外俩港口压根就没啥作用(这个实际上非常奇怪，因为我们从之前的统计图上并没有看到S港口的获救率非常低，所以也许可以考虑把登船港口这个feature去掉试试)。\n",
    "* 船票Fare有小幅度的正相关(并不意味着这个feature作用不大，有可能是我们细化的程度还不够，举个例子，说不定我们得对它离散化，再分至各个乘客等级上？)\n",
    "\n",
    "噢啦，观察完了，我们现在有一些想法了，但是怎么样才知道，哪些优化的方法是promising的呢？<br>\n",
    "\n",
    "恩，要靠交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.00289178, 0.00454783, 0.00681782, 0.00401807, 0.003932  ]), 'score_time': array([0.00038505, 0.00071597, 0.00074029, 0.00474787, 0.00062776]), 'test_score': array([0.81564246, 0.80898876, 0.78651685, 0.78651685, 0.81460674])}\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import cross_validation\n",
    "# from sklearn import cross_validate\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# 简单看看打分情况\n",
    "clf = linear_model.LogisticRegression(C=1.0, penalty='l1', solver='liblinear', tol=1e-6)\n",
    "all_data = df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\n",
    "X = all_data.values[:,1:]\n",
    "y = all_data.values[:,0]\n",
    "result = cross_validate(clf, X, y, cv=5)\n",
    "print(result)\n",
    "\n",
    "\n",
    "# 分割数据\n",
    "split_train, split_cv = sklearn.model_selection.train_test_split(df, test_size=0.3, random_state=0)\n",
    "train_df = split_train.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\n",
    "# 生成模型\n",
    "clf = linear_model.LogisticRegression(C=1.0, penalty='l1', solver='liblinear', tol=1e-6)\n",
    "clf.fit(train_df.values[:,1:], train_df.values[:,0])\n",
    "\n",
    "\n",
    "\n",
    "# 对cross validation数据进行预测\n",
    "\n",
    "cv_df = split_cv.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\n",
    "predictions = clf.predict(cv_df.values[:,1:])\n",
    "# split_cv[ predictions != cv_df.values[:,0] ].drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin_No</th>\n",
       "      <th>Cabin_Yes</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Age_scaled</th>\n",
       "      <th>Fare_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.840715</td>\n",
       "      <td>-0.357308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.107264</td>\n",
       "      <td>-0.496405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.662518</td>\n",
       "      <td>-0.061999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.474286</td>\n",
       "      <td>2.301729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.047512</td>\n",
       "      <td>-0.341452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759992</td>\n",
       "      <td>-0.648422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171656</td>\n",
       "      <td>-0.336334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.194330</td>\n",
       "      <td>-0.357391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.855015</td>\n",
       "      <td>-0.497496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.848089</td>\n",
       "      <td>-0.090272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  SibSp  Parch  Cabin_No  Cabin_Yes  Embarked_C  Embarked_Q  \\\n",
       "495         0      0      0         1          0           1           0   \n",
       "648         0      0      0         1          0           0           0   \n",
       "278         0      4      1         1          0           0           1   \n",
       "31          1      1      0         0          1           1           0   \n",
       "255         1      0      2         1          0           1           0   \n",
       "..        ...    ...    ...       ...        ...         ...         ...   \n",
       "263         0      0      0         0          1           0           0   \n",
       "718         0      0      0         1          0           0           1   \n",
       "620         0      1      0         1          0           1           0   \n",
       "786         1      0      0         1          0           0           0   \n",
       "64          0      0      0         1          0           1           0   \n",
       "\n",
       "     Embarked_S  Sex_female  Sex_male  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "495           0           0         1         0         0         1   \n",
       "648           1           0         1         0         0         1   \n",
       "278           0           0         1         0         0         1   \n",
       "31            0           1         0         1         0         0   \n",
       "255           0           1         0         0         0         1   \n",
       "..          ...         ...       ...       ...       ...       ...   \n",
       "263           1           0         1         1         0         0   \n",
       "718           0           0         1         0         0         1   \n",
       "620           0           0         1         0         0         1   \n",
       "786           1           1         0         0         0         1   \n",
       "64            0           0         1         1         0         0   \n",
       "\n",
       "     Age_scaled  Fare_scaled  \n",
       "495   -0.840715    -0.357308  \n",
       "648    0.107264    -0.496405  \n",
       "278   -1.662518    -0.061999  \n",
       "31     0.474286     2.301729  \n",
       "255   -0.047512    -0.341452  \n",
       "..          ...          ...  \n",
       "263    0.759992    -0.648422  \n",
       "718   -0.171656    -0.336334  \n",
       "620   -0.194330    -0.357391  \n",
       "786   -0.855015    -0.497496  \n",
       "64     0.848089    -0.090272  \n",
       "\n",
       "[268 rows x 15 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单看看打分情况\n",
    "clf = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "all_data = df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\n",
    "X = all_data.values[:,1:]\n",
    "y = all_data.values[:,0]\n",
    "\n",
    "# cross_validation.cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tong.xing/.local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tong.xing/.local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tong.xing/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tong.xing/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00015426, 0.0003171 , 0.00013709, 0.00013089, 0.00012994]),\n",
       " 'score_time': array([0., 0., 0., 0., 0.]),\n",
       " 'test_score': array([nan, nan, nan, nan, nan])}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn update\n",
    "cross_validate(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Arnold-Franchi, Mrs. Josef (Josefine Franchi)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>349237</td>\n",
       "      <td>17.8000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Woolner, Mr. Hugh</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19947</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>C52</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Moubarek, Master. Gerios</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2661</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Miss. Erna Alexandra</td>\n",
       "      <td>female</td>\n",
       "      <td>17.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3101281</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Backstrom, Mrs. Karl Alfred (Maria Mathilda Gu...</td>\n",
       "      <td>female</td>\n",
       "      <td>33.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3101278</td>\n",
       "      <td>15.8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Jussila, Miss. Katriina</td>\n",
       "      <td>female</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4136</td>\n",
       "      <td>9.8250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Boulos, Mrs. Joseph (Sultana)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2678</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Cohen, Mr. Gurshon \"Gus\"</td>\n",
       "      <td>male</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 3540</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Zabour, Miss. Thamine</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Strom, Mrs. Wilhelm (Elna Matilda Persson)</td>\n",
       "      <td>female</td>\n",
       "      <td>29.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>347054</td>\n",
       "      <td>10.4625</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asplund, Master. Edvin Rojj Felix</td>\n",
       "      <td>male</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>347077</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Henry, Miss. Delia</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>382649</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Persson, Mr. Ernst Ulrik</td>\n",
       "      <td>male</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>347083</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Tornquist, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Abbott, Mrs. Stanton (Rosa Hunt)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C.A. 2673</td>\n",
       "      <td>20.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>284</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Dorking, Mr. Edward Arthur</td>\n",
       "      <td>male</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 10482</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Haas, Miss. Aloisia</td>\n",
       "      <td>female</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349236</td>\n",
       "      <td>8.8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Saalfeld, Mr. Adolphe</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19988</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>C106</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>McCoy, Mr. Bernard</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>367226</td>\n",
       "      <td>23.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>313</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Lahtinen, Mrs. William (Anna Sylfven)</td>\n",
       "      <td>female</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>250651</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>339</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Dahl, Mr. Karl Edwart</td>\n",
       "      <td>male</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7598</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Barbara, Mrs. (Catherine David)</td>\n",
       "      <td>female</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2691</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>391</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carter, Mr. William Ernest</td>\n",
       "      <td>male</td>\n",
       "      <td>36.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113760</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Jussila, Miss. Mari Aina</td>\n",
       "      <td>female</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4137</td>\n",
       "      <td>9.8250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>448</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Seward, Mr. Frederic Kimber</td>\n",
       "      <td>male</td>\n",
       "      <td>34.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113794</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Strandberg, Miss. Ida Sofia</td>\n",
       "      <td>female</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7553</td>\n",
       "      <td>9.8375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>484</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Turkula, Mrs. (Hedwig)</td>\n",
       "      <td>female</td>\n",
       "      <td>63.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4134</td>\n",
       "      <td>9.5875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>490</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Coutts, Master. Eden Leslie \"Neville\"</td>\n",
       "      <td>male</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C.A. 37671</td>\n",
       "      <td>15.9000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Canavan, Miss. Mary</td>\n",
       "      <td>female</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>364846</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Laitinen, Miss. Kristina Sofia</td>\n",
       "      <td>female</td>\n",
       "      <td>37.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4135</td>\n",
       "      <td>9.5875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Penasco y Castellana, Mr. Victor de Satode</td>\n",
       "      <td>male</td>\n",
       "      <td>18.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C65</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>565</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Meanwell, Miss. (Marion Ogden)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 392087</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>568</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Mrs. Nils (Alma Cornelia Berglund)</td>\n",
       "      <td>female</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>571</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Harris, Mr. George</td>\n",
       "      <td>male</td>\n",
       "      <td>62.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S.W./PP 752</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>588</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Frolicher-Stehli, Mr. Maxmillian</td>\n",
       "      <td>male</td>\n",
       "      <td>60.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13567</td>\n",
       "      <td>79.2000</td>\n",
       "      <td>B41</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>643</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Skoog, Miss. Margit Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>347088</td>\n",
       "      <td>27.9000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>644</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Foo, Mr. Choong</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1601</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>648</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Simonius-Blumer, Col. Oberst Alfons</td>\n",
       "      <td>male</td>\n",
       "      <td>56.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13213</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A26</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hegarty, Miss. Hanora \"Nora\"</td>\n",
       "      <td>female</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>365226</td>\n",
       "      <td>6.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>681</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Peters, Miss. Katie</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330935</td>\n",
       "      <td>8.1375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>713</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Taylor, Mr. Elmer Zebley</td>\n",
       "      <td>male</td>\n",
       "      <td>48.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19996</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>C126</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>741</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hawksford, Mr. Walter James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16988</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>D45</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>763</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Barah, Mr. Hanna Assi</td>\n",
       "      <td>male</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2663</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>789</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Dean, Master. Bertram Vere</td>\n",
       "      <td>male</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>C.A. 2315</td>\n",
       "      <td>20.5750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>804</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Thomas, Master. Assad Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2625</td>\n",
       "      <td>8.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>839</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Chip, Mr. Chang</td>\n",
       "      <td>male</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1601</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>840</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Marechal, Mr. Pierre</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11774</td>\n",
       "      <td>29.7000</td>\n",
       "      <td>C47</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>853</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Boulos, Miss. Nourelain</td>\n",
       "      <td>female</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2678</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dahlberg, Miss. Gerda Ulrika</td>\n",
       "      <td>female</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "14            15         0       3   \n",
       "49            50         0       3   \n",
       "55            56         1       1   \n",
       "65            66         1       3   \n",
       "68            69         1       3   \n",
       "85            86         1       3   \n",
       "113          114         0       3   \n",
       "140          141         0       3   \n",
       "204          205         1       3   \n",
       "240          241         0       3   \n",
       "251          252         0       3   \n",
       "261          262         1       3   \n",
       "264          265         0       3   \n",
       "267          268         1       3   \n",
       "271          272         1       3   \n",
       "279          280         1       3   \n",
       "283          284         1       3   \n",
       "293          294         0       3   \n",
       "298          299         1       1   \n",
       "301          302         1       3   \n",
       "312          313         0       2   \n",
       "338          339         1       3   \n",
       "362          363         0       3   \n",
       "390          391         1       1   \n",
       "402          403         0       3   \n",
       "447          448         1       1   \n",
       "474          475         0       3   \n",
       "483          484         1       3   \n",
       "489          490         1       3   \n",
       "501          502         0       3   \n",
       "503          504         0       3   \n",
       "505          506         0       1   \n",
       "564          565         0       3   \n",
       "567          568         0       3   \n",
       "570          571         1       2   \n",
       "587          588         1       1   \n",
       "642          643         0       3   \n",
       "643          644         1       3   \n",
       "647          648         1       1   \n",
       "654          655         0       3   \n",
       "680          681         0       3   \n",
       "712          713         1       1   \n",
       "740          741         1       1   \n",
       "762          763         1       3   \n",
       "788          789         1       3   \n",
       "803          804         1       3   \n",
       "838          839         1       3   \n",
       "839          840         1       1   \n",
       "852          853         0       3   \n",
       "882          883         0       3   \n",
       "\n",
       "                                                  Name     Sex    Age  SibSp  \\\n",
       "14                Vestrom, Miss. Hulda Amanda Adolfina  female  14.00      0   \n",
       "49       Arnold-Franchi, Mrs. Josef (Josefine Franchi)  female  18.00      1   \n",
       "55                                   Woolner, Mr. Hugh    male    NaN      0   \n",
       "65                            Moubarek, Master. Gerios    male    NaN      1   \n",
       "68                     Andersson, Miss. Erna Alexandra  female  17.00      4   \n",
       "85   Backstrom, Mrs. Karl Alfred (Maria Mathilda Gu...  female  33.00      3   \n",
       "113                            Jussila, Miss. Katriina  female  20.00      1   \n",
       "140                      Boulos, Mrs. Joseph (Sultana)  female    NaN      0   \n",
       "204                           Cohen, Mr. Gurshon \"Gus\"    male  18.00      0   \n",
       "240                              Zabour, Miss. Thamine  female    NaN      1   \n",
       "251         Strom, Mrs. Wilhelm (Elna Matilda Persson)  female  29.00      1   \n",
       "261                  Asplund, Master. Edvin Rojj Felix    male   3.00      4   \n",
       "264                                 Henry, Miss. Delia  female    NaN      0   \n",
       "267                           Persson, Mr. Ernst Ulrik    male  25.00      1   \n",
       "271                       Tornquist, Mr. William Henry    male  25.00      0   \n",
       "279                   Abbott, Mrs. Stanton (Rosa Hunt)  female  35.00      1   \n",
       "283                         Dorking, Mr. Edward Arthur    male  19.00      0   \n",
       "293                                Haas, Miss. Aloisia  female  24.00      0   \n",
       "298                              Saalfeld, Mr. Adolphe    male    NaN      0   \n",
       "301                                 McCoy, Mr. Bernard    male    NaN      2   \n",
       "312              Lahtinen, Mrs. William (Anna Sylfven)  female  26.00      1   \n",
       "338                              Dahl, Mr. Karl Edwart    male  45.00      0   \n",
       "362                    Barbara, Mrs. (Catherine David)  female  45.00      0   \n",
       "390                         Carter, Mr. William Ernest    male  36.00      1   \n",
       "402                           Jussila, Miss. Mari Aina  female  21.00      1   \n",
       "447                        Seward, Mr. Frederic Kimber    male  34.00      0   \n",
       "474                        Strandberg, Miss. Ida Sofia  female  22.00      0   \n",
       "483                             Turkula, Mrs. (Hedwig)  female  63.00      0   \n",
       "489              Coutts, Master. Eden Leslie \"Neville\"    male   9.00      1   \n",
       "501                                Canavan, Miss. Mary  female  21.00      0   \n",
       "503                     Laitinen, Miss. Kristina Sofia  female  37.00      0   \n",
       "505         Penasco y Castellana, Mr. Victor de Satode    male  18.00      1   \n",
       "564                     Meanwell, Miss. (Marion Ogden)  female    NaN      0   \n",
       "567        Palsson, Mrs. Nils (Alma Cornelia Berglund)  female  29.00      0   \n",
       "570                                 Harris, Mr. George    male  62.00      0   \n",
       "587                   Frolicher-Stehli, Mr. Maxmillian    male  60.00      1   \n",
       "642                      Skoog, Miss. Margit Elizabeth  female   2.00      3   \n",
       "643                                    Foo, Mr. Choong    male    NaN      0   \n",
       "647                Simonius-Blumer, Col. Oberst Alfons    male  56.00      0   \n",
       "654                       Hegarty, Miss. Hanora \"Nora\"  female  18.00      0   \n",
       "680                                Peters, Miss. Katie  female    NaN      0   \n",
       "712                           Taylor, Mr. Elmer Zebley    male  48.00      1   \n",
       "740                        Hawksford, Mr. Walter James    male    NaN      0   \n",
       "762                              Barah, Mr. Hanna Assi    male  20.00      0   \n",
       "788                         Dean, Master. Bertram Vere    male   1.00      1   \n",
       "803                    Thomas, Master. Assad Alexander    male   0.42      0   \n",
       "838                                    Chip, Mr. Chang    male  32.00      0   \n",
       "839                               Marechal, Mr. Pierre    male    NaN      0   \n",
       "852                            Boulos, Miss. Nourelain  female   9.00      1   \n",
       "882                       Dahlberg, Miss. Gerda Ulrika  female  22.00      0   \n",
       "\n",
       "     Parch             Ticket      Fare    Cabin Embarked  \n",
       "14       0             350406    7.8542      NaN        S  \n",
       "49       0             349237   17.8000      NaN        S  \n",
       "55       0              19947   35.5000      C52        S  \n",
       "65       1               2661   15.2458      NaN        C  \n",
       "68       2            3101281    7.9250      NaN        S  \n",
       "85       0            3101278   15.8500      NaN        S  \n",
       "113      0               4136    9.8250      NaN        S  \n",
       "140      2               2678   15.2458      NaN        C  \n",
       "204      0           A/5 3540    8.0500      NaN        S  \n",
       "240      0               2665   14.4542      NaN        C  \n",
       "251      1             347054   10.4625       G6        S  \n",
       "261      2             347077   31.3875      NaN        S  \n",
       "264      0             382649    7.7500      NaN        Q  \n",
       "267      0             347083    7.7750      NaN        S  \n",
       "271      0               LINE    0.0000      NaN        S  \n",
       "279      1          C.A. 2673   20.2500      NaN        S  \n",
       "283      0         A/5. 10482    8.0500      NaN        S  \n",
       "293      0             349236    8.8500      NaN        S  \n",
       "298      0              19988   30.5000     C106        S  \n",
       "301      0             367226   23.2500      NaN        Q  \n",
       "312      1             250651   26.0000      NaN        S  \n",
       "338      0               7598    8.0500      NaN        S  \n",
       "362      1               2691   14.4542      NaN        C  \n",
       "390      2             113760  120.0000  B96 B98        S  \n",
       "402      0               4137    9.8250      NaN        S  \n",
       "447      0             113794   26.5500      NaN        S  \n",
       "474      0               7553    9.8375      NaN        S  \n",
       "483      0               4134    9.5875      NaN        S  \n",
       "489      1         C.A. 37671   15.9000      NaN        S  \n",
       "501      0             364846    7.7500      NaN        Q  \n",
       "503      0               4135    9.5875      NaN        S  \n",
       "505      0           PC 17758  108.9000      C65        C  \n",
       "564      0  SOTON/O.Q. 392087    8.0500      NaN        S  \n",
       "567      4             349909   21.0750      NaN        S  \n",
       "570      0        S.W./PP 752   10.5000      NaN        S  \n",
       "587      1              13567   79.2000      B41        C  \n",
       "642      2             347088   27.9000      NaN        S  \n",
       "643      0               1601   56.4958      NaN        S  \n",
       "647      0              13213   35.5000      A26        C  \n",
       "654      0             365226    6.7500      NaN        Q  \n",
       "680      0             330935    8.1375      NaN        Q  \n",
       "712      0              19996   52.0000     C126        S  \n",
       "740      0              16988   30.0000      D45        S  \n",
       "762      0               2663    7.2292      NaN        C  \n",
       "788      2          C.A. 2315   20.5750      NaN        S  \n",
       "803      1               2625    8.5167      NaN        C  \n",
       "838      0               1601   56.4958      NaN        S  \n",
       "839      0              11774   29.7000      C47        C  \n",
       "852      1               2678   15.2458      NaN        C  \n",
       "882      0               7552   10.5167      NaN        S  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去除预测错误的case看原始dataframe数据\n",
    "#split_cv['PredictResult'] = predictions\n",
    "origin_data_train = pd.read_csv(\"Train.csv\")\n",
    "bad_cases = origin_data_train.loc[origin_data_train['PassengerId'].isin(split_cv[predictions != cv_df.values[:,0]]['PassengerId'].values)]\n",
    "bad_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对比bad case，我们仔细看看我们预测错的样本，到底是哪些特征有问题，咱们处理得还不够细？<br>\n",
    "\n",
    "我们随便列一些可能可以做的优化操作：<br>\n",
    "\n",
    "* Age属性不使用现在的拟合方式，而是根据名称中的『Mr』『Mrs』『Miss』等的平均值进行填充。\n",
    "* Age不做成一个连续值属性，而是使用一个步长进行离散化，变成离散的类目feature。\n",
    "* Cabin再细化一些，对于有记录的Cabin属性，我们将其分为前面的字母部分(我猜是位置和船层之类的信息) 和 后面的数字部分(应该是房间号，有意思的事情是，如果你仔细看看原始数据，你会发现，这个值大的情况下，似乎获救的可能性高一些)。\n",
    "* Pclass和Sex俩太重要了，我们试着用它们去组出一个组合属性来试试，这也是另外一种程度的细化。\n",
    "* 单加一个Child字段，Age<=12的，设为1，其余为0(你去看看数据，确实小盆友优先程度很高啊)\n",
    "* 如果名字里面有『Mrs』，而Parch>1的，我们猜测她可能是一个母亲，应该获救的概率也会提高，因此可以多加一个Mother字段，此种情况下设为1，其余情况下设为0\n",
    "* 登船港口可以考虑先去掉试试(Q和C本来就没权重，S有点诡异)\n",
    "* 把堂兄弟/兄妹 和 Parch 还有自己 个数加在一起组一个Family_size字段(考虑到大家族可能对最后的结果有影响)\n",
    "* Name是一个我们一直没有触碰的属性，我们可以做一些简单的处理，比如说男性中带某些字眼的(‘Capt’, ‘Don’, ‘Major’, ‘Sir’)可以统一到一个Title，女性也一样。\n",
    "\n",
    "大家接着往下挖掘，可能还可以想到更多可以细挖的部分。我这里先列这些了，然后我们可以使用手头上的”train_df”和”cv_df”开始试验这些feature engineering的tricks是否有效了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>450</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Peuchen, Major. Arthur Godfrey</td>\n",
       "      <td>male</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113786</td>\n",
       "      <td>30.50</td>\n",
       "      <td>Yes</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>537</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Butt, Major. Archibald Willingham</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113050</td>\n",
       "      <td>26.55</td>\n",
       "      <td>Yes</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                               Name   Sex  \\\n",
       "449          450         1       1     Peuchen, Major. Arthur Godfrey  male   \n",
       "536          537         0       1  Butt, Major. Archibald Willingham  male   \n",
       "\n",
       "      Age  SibSp  Parch  Ticket   Fare Cabin Embarked  \n",
       "449  52.0      0      0  113786  30.50   Yes        S  \n",
       "536  45.0      0      0  113050  26.55   Yes        S  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[data_train['Name'].str.contains(\"Major\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='liblinear', tol=1e-06)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"Train.csv\")\n",
    "data_train['Sex_Pclass'] = data_train.Sex + \"_\" + data_train.Pclass.map(str)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    " \n",
    "### 使用 RandomForestClassifier 填补缺失的年龄属性\n",
    "def set_missing_ages(df):\n",
    "    \n",
    "    # 把已有的数值型特征取出来丢进Random Forest Regressor中\n",
    "    age_df = df[['Age','Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "\n",
    "    # 乘客分成已知年龄和未知年龄两部分\n",
    "    known_age = age_df[age_df.Age.notnull()].values\n",
    "    unknown_age = age_df[age_df.Age.isnull()].values\n",
    "\n",
    "    # y即目标年龄\n",
    "    y = known_age[:, 0]\n",
    "\n",
    "    # X即特征属性值\n",
    "    X = known_age[:, 1:]\n",
    "\n",
    "    # fit到RandomForestRegressor之中\n",
    "    rfr = RandomForestRegressor(random_state=0, n_estimators=2000, n_jobs=-1)\n",
    "    rfr.fit(X, y)\n",
    "    \n",
    "    # 用得到的模型进行未知年龄结果预测\n",
    "    predictedAges = rfr.predict(unknown_age[:, 1::])\n",
    "    \n",
    "    # 用得到的预测结果填补原缺失数据\n",
    "    df.loc[ (df.Age.isnull()), 'Age' ] = predictedAges \n",
    "    \n",
    "    return df, rfr\n",
    "\n",
    "def set_Cabin_type(df):\n",
    "    df.loc[ (df.Cabin.notnull()), 'Cabin' ] = \"Yes\"\n",
    "    df.loc[ (df.Cabin.isnull()), 'Cabin' ] = \"No\"\n",
    "    return df\n",
    "\n",
    "data_train, rfr = set_missing_ages(data_train)\n",
    "data_train = set_Cabin_type(data_train)\n",
    "\n",
    "dummies_Cabin = pd.get_dummies(data_train['Cabin'], prefix= 'Cabin')\n",
    "dummies_Embarked = pd.get_dummies(data_train['Embarked'], prefix= 'Embarked')\n",
    "dummies_Sex = pd.get_dummies(data_train['Sex'], prefix= 'Sex')\n",
    "dummies_Pclass = pd.get_dummies(data_train['Pclass'], prefix= 'Pclass')\n",
    "dummies_Sex_Pclass = pd.get_dummies(data_train['Sex_Pclass'], prefix= 'Sex_Pclass')\n",
    "\n",
    "\n",
    "df = pd.concat([data_train, dummies_Cabin, dummies_Embarked, dummies_Sex, dummies_Pclass, dummies_Sex_Pclass], axis=1)\n",
    "df.drop(['Pclass', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Sex_Pclass'], axis=1, inplace=True)\n",
    "import sklearn.preprocessing as preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "age_scale_param = scaler.fit(df_age)\n",
    "df['Age_scaled'] = scaler.fit_transform(df_age, age_scale_param)\n",
    "fare_scale_param = scaler.fit(df_fare)\n",
    "df['Fare_scaled'] = scaler.fit_transform(df_fare, fare_scale_param)\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "train_df = df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass.*')\n",
    "train_np = train_df.values\n",
    "\n",
    "# y即Survival结果\n",
    "y = train_np[:, 0]\n",
    "\n",
    "# X即特征属性值\n",
    "X = train_np[:, 1:]\n",
    "\n",
    "# fit到RandomForestRegressor之中\n",
    "clf = linear_model.LogisticRegression(C=1.0, penalty='l1', solver='liblinear', tol=1e-6)\n",
    "clf.fit(X, y)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = df['Age'].values\n",
    "df_age = df_age.reshape(-1, 1)\n",
    "\n",
    "df_fare = df['Fare'].values\n",
    "df_fare = df_fare.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_age = df_test['Age'].values\n",
    "df_test_age = df_test_age.reshape(-1, 1)\n",
    "\n",
    "df_test_fare = df_test['Fare'].values\n",
    "df_test_fare = df_test_fare.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin_No</th>\n",
       "      <th>Cabin_Yes</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>...</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_Pclass_female_1</th>\n",
       "      <th>Sex_Pclass_female_2</th>\n",
       "      <th>Sex_Pclass_female_3</th>\n",
       "      <th>Sex_Pclass_male_1</th>\n",
       "      <th>Sex_Pclass_male_2</th>\n",
       "      <th>Sex_Pclass_male_3</th>\n",
       "      <th>Age_scaled</th>\n",
       "      <th>Fare_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.307526</td>\n",
       "      <td>-0.496637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.256242</td>\n",
       "      <td>-0.511497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.394702</td>\n",
       "      <td>-0.463335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.261704</td>\n",
       "      <td>-0.481704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.641190</td>\n",
       "      <td>-0.416740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>30.705727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019551</td>\n",
       "      <td>-0.492680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.649064</td>\n",
       "      <td>1.314641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611115</td>\n",
       "      <td>-0.507017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>30.705727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019551</td>\n",
       "      <td>-0.492680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>25.755877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.356130</td>\n",
       "      <td>-0.236263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId        Age  SibSp  Parch      Fare  Cabin_No  Cabin_Yes  \\\n",
       "0            892  34.500000      0      0    7.8292         1          0   \n",
       "1            893  47.000000      1      0    7.0000         1          0   \n",
       "2            894  62.000000      0      0    9.6875         1          0   \n",
       "3            895  27.000000      0      0    8.6625         1          0   \n",
       "4            896  22.000000      1      1   12.2875         1          0   \n",
       "..           ...        ...    ...    ...       ...       ...        ...   \n",
       "413         1305  30.705727      0      0    8.0500         1          0   \n",
       "414         1306  39.000000      0      0  108.9000         0          1   \n",
       "415         1307  38.500000      0      0    7.2500         1          0   \n",
       "416         1308  30.705727      0      0    8.0500         1          0   \n",
       "417         1309  25.755877      1      1   22.3583         1          0   \n",
       "\n",
       "     Embarked_C  Embarked_Q  Embarked_S  ...  Pclass_2  Pclass_3  \\\n",
       "0             0           1           0  ...         0         1   \n",
       "1             0           0           1  ...         0         1   \n",
       "2             0           1           0  ...         1         0   \n",
       "3             0           0           1  ...         0         1   \n",
       "4             0           0           1  ...         0         1   \n",
       "..          ...         ...         ...  ...       ...       ...   \n",
       "413           0           0           1  ...         0         1   \n",
       "414           1           0           0  ...         0         0   \n",
       "415           0           0           1  ...         0         1   \n",
       "416           0           0           1  ...         0         1   \n",
       "417           1           0           0  ...         0         1   \n",
       "\n",
       "     Sex_Pclass_female_1  Sex_Pclass_female_2  Sex_Pclass_female_3  \\\n",
       "0                      0                    0                    0   \n",
       "1                      0                    0                    1   \n",
       "2                      0                    0                    0   \n",
       "3                      0                    0                    0   \n",
       "4                      0                    0                    1   \n",
       "..                   ...                  ...                  ...   \n",
       "413                    0                    0                    0   \n",
       "414                    1                    0                    0   \n",
       "415                    0                    0                    0   \n",
       "416                    0                    0                    0   \n",
       "417                    0                    0                    0   \n",
       "\n",
       "     Sex_Pclass_male_1  Sex_Pclass_male_2  Sex_Pclass_male_3  Age_scaled  \\\n",
       "0                    0                  0                  1    0.307526   \n",
       "1                    0                  0                  0    1.256242   \n",
       "2                    0                  1                  0    2.394702   \n",
       "3                    0                  0                  1   -0.261704   \n",
       "4                    0                  0                  0   -0.641190   \n",
       "..                 ...                ...                ...         ...   \n",
       "413                  0                  0                  1    0.019551   \n",
       "414                  0                  0                  0    0.649064   \n",
       "415                  0                  0                  1    0.611115   \n",
       "416                  0                  0                  1    0.019551   \n",
       "417                  0                  0                  1   -0.356130   \n",
       "\n",
       "     Fare_scaled  \n",
       "0      -0.496637  \n",
       "1      -0.511497  \n",
       "2      -0.463335  \n",
       "3      -0.481704  \n",
       "4      -0.416740  \n",
       "..           ...  \n",
       "413    -0.492680  \n",
       "414     1.314641  \n",
       "415    -0.507017  \n",
       "416    -0.492680  \n",
       "417    -0.236263  \n",
       "\n",
       "[418 rows x 23 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(\"test.csv\")\n",
    "data_test.loc[ (data_test.Fare.isnull()), 'Fare' ] = 0\n",
    "data_test['Sex_Pclass'] = data_test.Sex + \"_\" + data_test.Pclass.map(str)\n",
    "# 接着我们对test_data做和train_data中一致的特征变换\n",
    "# 首先用同样的RandomForestRegressor模型填上丢失的年龄\n",
    "tmp_df = data_test[['Age','Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "null_age = tmp_df[data_test.Age.isnull()].values\n",
    "# 根据特征属性X预测年龄并补上\n",
    "X = null_age[:, 1:]\n",
    "predictedAges = rfr.predict(X)\n",
    "data_test.loc[ (data_test.Age.isnull()), 'Age' ] = predictedAges\n",
    "\n",
    "data_test = set_Cabin_type(data_test)\n",
    "dummies_Cabin = pd.get_dummies(data_test['Cabin'], prefix= 'Cabin')\n",
    "dummies_Embarked = pd.get_dummies(data_test['Embarked'], prefix= 'Embarked')\n",
    "dummies_Sex = pd.get_dummies(data_test['Sex'], prefix= 'Sex')\n",
    "dummies_Pclass = pd.get_dummies(data_test['Pclass'], prefix= 'Pclass')\n",
    "dummies_Sex_Pclass = pd.get_dummies(data_test['Sex_Pclass'], prefix= 'Sex_Pclass')\n",
    "\n",
    "\n",
    "df_test = pd.concat([data_test, dummies_Cabin, dummies_Embarked, dummies_Sex, dummies_Pclass, dummies_Sex_Pclass], axis=1)\n",
    "df_test.drop(['Pclass', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Sex_Pclass'], axis=1, inplace=True)\n",
    "df_test['Age_scaled'] = scaler.fit_transform(df_test_age, age_scale_param)\n",
    "df_test['Fare_scaled'] = scaler.fit_transform(df_test_fare, fare_scale_param)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_test.filter(regex='Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass.*')\n",
    "predictions = clf.predict(test)\n",
    "result = pd.DataFrame({'PassengerId':data_test['PassengerId'].values, 'Survived':predictions.astype(np.int32)})\n",
    "result.to_csv(\"logistic_regression_predictions2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>一般做到后期，咱们要进行模型优化的方法就是模型融合啦<br>\n",
    "先解释解释啥叫模型融合哈，我们还是举几个例子直观理解一下好了。<br><br>\n",
    "\n",
    "大家都看过知识问答的综艺节目中，求助现场观众时候，让观众投票，最高的答案作为自己的答案的形式吧，每个人都有一个判定结果，最后我们相信答案在大多数人手里。<br>\n",
    "\n",
    "再通俗一点举个例子。你和你班某数学大神关系好，每次作业都『模仿』他的，于是绝大多数情况下，他做对了，你也对了。突然某一天大神脑子犯糊涂，手一抖，写错了一个数，于是…恩，你也只能跟着错了。 <br>\n",
    "我们再来看看另外一个场景，你和你班5个数学大神关系都很好，每次都把他们作业拿过来，对比一下，再『自己做』，那你想想，如果哪天某大神犯糊涂了，写错了，but另外四个写对了啊，那你肯定相信另外4人的是正确答案吧？<br>\n",
    "\n",
    "最简单的模型融合大概就是这么个意思，比如分类问题，当我们手头上有一堆在同一份数据集上训练得到的分类器(比如logistic regression，SVM，KNN，random forest，神经网络)，那我们让他们都分别去做判定，然后对结果做投票统计，取票数最多的结果为最后结果。<br>\n",
    "\n",
    "bingo，问题就这么完美的解决了。<br>\n",
    "\n",
    "模型融合可以比较好地缓解，训练过程中产生的过拟合问题，从而对于结果的准确度提升有一定的帮助。<br>\n",
    "\n",
    "话说回来，回到我们现在的问题。你看，我们现在只讲了logistic regression，如果我们还想用这个融合思想去提高我们的结果，我们该怎么做呢？<br>\n",
    "\n",
    "既然这个时候模型没得选，那咱们就在数据上动动手脚咯。大家想想，如果模型出现过拟合现在，一定是在我们的训练上出现拟合过度造成的对吧。<br>\n",
    "\n",
    "那我们干脆就不要用全部的训练集，每次取训练集的一个subset，做训练，这样，我们虽然用的是同一个机器学习算法，但是得到的模型却是不一样的；同时，因为我们没有任何一份子数据集是全的，因此即使出现过拟合，也是在子训练集上出现过拟合，而不是全体数据上，这样做一个融合，可能对最后的结果有一定的帮助。对，这就是常用的Bagging。<br>\n",
    "\n",
    "我们用scikit-learn里面的Bagging来完成上面的思路，过程非常简单。代码如下：<br><br><font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "train_df = df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass.*|Mother|Child|Family|Title')\n",
    "train_np = train_df.values\n",
    "\n",
    "# y即Survival结果\n",
    "y = train_np[:, 0]\n",
    "\n",
    "# X即特征属性值\n",
    "X = train_np[:, 1:]\n",
    "\n",
    "# fit到BaggingRegressor之中\n",
    "clf = linear_model.LogisticRegression(C=1.0, penalty='l1', solver='liblinear', tol=1e-6)\n",
    "bagging_clf = BaggingRegressor(clf, n_estimators=10, max_samples=0.8, max_features=1.0, bootstrap=True, bootstrap_features=False, n_jobs=-1)\n",
    "bagging_clf.fit(X, y)\n",
    "\n",
    "test = df_test.filter(regex='Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass.*|Mother|Child|Family|Title')\n",
    "predictions = bagging_clf.predict(test)\n",
    "result = pd.DataFrame({'PassengerId':data_test['PassengerId'].values, 'Survived':predictions.astype(np.int32)})\n",
    "result.to_csv(\"./logistic_regression_predictions2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y即Survival结果\n",
    "y = train_np[:, 0]\n",
    "\n",
    "# X即特征属性值\n",
    "X = train_np[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 20)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform darwin -- Python 3.7.7, pytest-5.4.1, py-1.8.1, pluggy-0.13.1\n",
      "rootdir: /Users/tong.xing/OneDrive - Northeastern University/Info7390/Kaggle_Titanic\n",
      "plugins: arraydiff-0.3, remotedata-0.3.2, openfiles-0.4.0, dash-1.19.0, hypothesis-5.8.3, doctestplus-0.5.0, astropy-header-0.1.2\n",
      "collected 26406 items / 10731 deselected / 15675 selected\n",
      "\n",
      "_build_utils/tests/test_circular_imports.py .                            [  0%]\n",
      "_build_utils/tests/test_scipy_version.py .                               [  0%]\n",
      "_lib/tests/test__gcutils.py ......                                       [  0%]\n",
      "_lib/tests/test__testutils.py ..                                         [  0%]\n",
      "_lib/tests/test__threadsafety.py ..                                      [  0%]\n",
      "_lib/tests/test__util.py ...\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! KeyboardInterrupt !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "/Users/tong.xing/opt/anaconda3/lib/python3.7/threading.py:296: KeyboardInterrupt\n",
      "(to show a full traceback on KeyboardInterrupt use --full-trace)\n",
      "=============== 15 passed, 10731 deselected in 811.34s (0:13:31) ===============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /Users/tong.xing/opt/anaconda3/lib/python3.7/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>下面是咱们用别的分类器解决这个问题的代码：</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv 0\n",
      "(891,) (891, 12)\n",
      "Fitting [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0.\n",
      " 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1.\n",
      " 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      " 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0.] folds for each of 1 candidates, totalling [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0.\n",
      " 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1.\n",
      " 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      " 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0.] fits\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-9c85f3da5b59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    192\u001b[0m grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=3,scoring='accuracy',\n\u001b[1;32m    193\u001b[0m cv= StratifiedShuffleSplit(Y_train, test_size=0.2, train_size=None, \n\u001b[0;32m--> 194\u001b[0;31m random_state=seed)).fit(X_train, Y_train)\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;31m# pipeline=Pipeline([ ('clf',clf) ])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \"\"\"\n\u001b[1;32m   1340\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1689\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1690\u001b[0m             \u001b[0;31m# if there are ties in the class-counts, we want\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m             \u001b[0;31m# to make sure to break them anew in each iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import  DataFrame\n",
    "from patsy import dmatrices\n",
    "import string\n",
    "from operator import itemgetter\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "# from sklearn.cross_validation import train_test_split,StratifiedShuffleSplit,StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit,StratifiedKFold\n",
    "\n",
    "##Read configuration parameters\n",
    "\n",
    "train_file=\"train.csv\"\n",
    "MODEL_PATH=\"./\"\n",
    "test_file=\"test.csv\"\n",
    "SUBMISSION_PATH=\"./\"\n",
    "seed= 0\n",
    "\n",
    "print(train_file, seed)\n",
    "\n",
    "# 输出得分\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "\n",
    "#清理和处理数据\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if str.find(big_string, substring) != -1:\n",
    "            return substring\n",
    "    print(big_string)\n",
    "    return np.nan\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "enc=preprocessing.OneHotEncoder()\n",
    "\n",
    "def clean_and_munge_data(df):\n",
    "    #处理缺省值\n",
    "    df.Fare = df.Fare.map(lambda x: np.nan if x==0 else x)\n",
    "    #处理一下名字，生成Title字段\n",
    "    title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\n",
    "                'Dr', 'Ms', 'Mlle','Col', 'Capt', 'Mme', 'Countess',\n",
    "                'Don', 'Jonkheer']\n",
    "    df['Title']=df['Name'].map(lambda x: substrings_in_string(x, title_list))\n",
    "\n",
    "    #处理特殊的称呼，全处理成mr, mrs, miss, master\n",
    "    def replace_titles(x):\n",
    "        title=x['Title']\n",
    "        if title in ['Mr','Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col']:\n",
    "            return 'Mr'\n",
    "        elif title in ['Master']:\n",
    "            return 'Master'\n",
    "        elif title in ['Countess', 'Mme','Mrs']:\n",
    "            return 'Mrs'\n",
    "        elif title in ['Mlle', 'Ms','Miss']:\n",
    "            return 'Miss'\n",
    "        elif title =='Dr':\n",
    "            if x['Sex']=='Male':\n",
    "                return 'Mr'\n",
    "            else:\n",
    "                return 'Mrs'\n",
    "        elif title =='':\n",
    "            if x['Sex']=='Male':\n",
    "                return 'Master'\n",
    "            else:\n",
    "                return 'Miss'\n",
    "        else:\n",
    "            return title\n",
    "\n",
    "    df['Title']=df.apply(replace_titles, axis=1)\n",
    "\n",
    "    #看看家族是否够大，咳咳\n",
    "    df['Family_Size']=df['SibSp']+df['Parch']\n",
    "    df['Family']=df['SibSp']*df['Parch']\n",
    "\n",
    "\n",
    "    df.loc[ (df.Fare.isnull())&(df.Pclass==1),'Fare'] =np.median(df[df['Pclass'] == 1]['Fare'].dropna())\n",
    "    df.loc[ (df.Fare.isnull())&(df.Pclass==2),'Fare'] =np.median( df[df['Pclass'] == 2]['Fare'].dropna())\n",
    "    df.loc[ (df.Fare.isnull())&(df.Pclass==3),'Fare'] = np.median(df[df['Pclass'] == 3]['Fare'].dropna())\n",
    "\n",
    "    df['Gender'] = df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "    df['AgeFill']=df['Age']\n",
    "    mean_ages = np.zeros(4)\n",
    "    mean_ages[0]=np.average(df[df['Title'] == 'Miss']['Age'].dropna())\n",
    "    mean_ages[1]=np.average(df[df['Title'] == 'Mrs']['Age'].dropna())\n",
    "    mean_ages[2]=np.average(df[df['Title'] == 'Mr']['Age'].dropna())\n",
    "    mean_ages[3]=np.average(df[df['Title'] == 'Master']['Age'].dropna())\n",
    "    df.loc[ (df.Age.isnull()) & (df.Title == 'Miss') ,'AgeFill'] = mean_ages[0]\n",
    "    df.loc[ (df.Age.isnull()) & (df.Title == 'Mrs') ,'AgeFill'] = mean_ages[1]\n",
    "    df.loc[ (df.Age.isnull()) & (df.Title == 'Mr') ,'AgeFill'] = mean_ages[2]\n",
    "    df.loc[ (df.Age.isnull()) & (df.Title == 'Master') ,'AgeFill'] = mean_ages[3]\n",
    "\n",
    "    df['AgeCat']=df['AgeFill']\n",
    "    df.loc[ (df.AgeFill<=10) ,'AgeCat'] = 'child'\n",
    "    df.loc[ (df.AgeFill>60),'AgeCat'] = 'aged'\n",
    "    df.loc[ (df.AgeFill>10) & (df.AgeFill <=30) ,'AgeCat'] = 'adult'\n",
    "    df.loc[ (df.AgeFill>30) & (df.AgeFill <=60) ,'AgeCat'] = 'senior'\n",
    "\n",
    "    df.Embarked = df.Embarked.fillna('S')\n",
    "\n",
    "\n",
    "    df.loc[ df.Cabin.isnull()==True,'Cabin'] = 0.5\n",
    "    df.loc[ df.Cabin.isnull()==False,'Cabin'] = 1.5\n",
    "\n",
    "    df['Fare_Per_Person']=df['Fare']/(df['Family_Size']+1)\n",
    "\n",
    "    #Age times class\n",
    "\n",
    "    df['AgeClass']=df['AgeFill']*df['Pclass']\n",
    "    df['ClassFare']=df['Pclass']*df['Fare_Per_Person']\n",
    "\n",
    "\n",
    "    df['HighLow']=df['Pclass']\n",
    "    df.loc[ (df.Fare_Per_Person<8) ,'HighLow'] = 'Low'\n",
    "    df.loc[ (df.Fare_Per_Person>=8) ,'HighLow'] = 'High'\n",
    "\n",
    "\n",
    "\n",
    "    le.fit(df['Sex'] )\n",
    "    x_sex=le.transform(df['Sex'])\n",
    "    df['Sex']=x_sex.astype(np.float)\n",
    "\n",
    "    le.fit( df['Ticket'])\n",
    "    x_Ticket=le.transform( df['Ticket'])\n",
    "    df['Ticket']=x_Ticket.astype(np.float)\n",
    "\n",
    "    le.fit(df['Title'])\n",
    "    x_title=le.transform(df['Title'])\n",
    "    df['Title'] =x_title.astype(np.float)\n",
    "\n",
    "    le.fit(df['HighLow'])\n",
    "    x_hl=le.transform(df['HighLow'])\n",
    "    df['HighLow']=x_hl.astype(np.float)\n",
    "\n",
    "\n",
    "    le.fit(df['AgeCat'])\n",
    "    x_age=le.transform(df['AgeCat'])\n",
    "    df['AgeCat'] =x_age.astype(np.float)\n",
    "\n",
    "    le.fit(df['Embarked'])\n",
    "    x_emb=le.transform(df['Embarked'])\n",
    "    df['Embarked']=x_emb.astype(np.float)\n",
    "\n",
    "    df = df.drop(['PassengerId','Name','Age','Cabin'], axis=1) #remove Name,Age and PassengerId\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "#读取数据\n",
    "traindf = pd.read_csv(train_file)\n",
    "\n",
    "##清洗数据\n",
    "df = clean_and_munge_data(traindf)\n",
    "########################################formula################################\n",
    " \n",
    "formula_ml='Survived~Pclass+C(Title)+Sex+C(AgeCat)+Fare_Per_Person+Fare+Family_Size' \n",
    "\n",
    "y_train, x_train = dmatrices(formula_ml, data=df, return_type='dataframe')\n",
    "y_train = np.asarray(y_train).ravel()\n",
    "print (y_train.shape,x_train.shape)\n",
    "\n",
    "##选择训练和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.2,random_state=seed)\n",
    "\n",
    "#初始化分类器\n",
    "clf=RandomForestClassifier(n_estimators=500, criterion='entropy', max_depth=5, min_samples_split=1,\n",
    "  min_samples_leaf=1, max_features='auto',    bootstrap=False, oob_score=False, n_jobs=1, random_state=seed,\n",
    "  verbose=0)\n",
    "\n",
    "###grid search找到最好的参数\n",
    "param_grid = dict( )\n",
    "\n",
    "##创建分类pipeline\n",
    "pipeline=Pipeline([ ('clf',clf) ])\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=3,scoring='accuracy',\n",
    "cv= StratifiedShuffleSplit(Y_train, test_size=0.2, train_size=None, \n",
    "random_state=seed)).fit(X_train, Y_train)\n",
    "\n",
    "# pipeline=Pipeline([ ('clf',clf) ])\n",
    "# grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=3,scoring='accuracy',\n",
    "# cv= StratifiedShuffleSplit(Y_train, n_iter=10, test_size=0.2, train_size=None, indices=None, \n",
    "# random_state=seed, n_iterations=None)).fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# 对结果打分\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(grid_search.best_estimator_)\n",
    "report(grid_search.grid_scores_)\n",
    " \n",
    "print('-----grid search end------------')\n",
    "print ('on all train set')\n",
    "scores = cross_val_score(grid_search.best_estimator_, x_train, y_train,cv=3,scoring='accuracy')\n",
    "print (scores.mean(),scores)\n",
    "print ('on test set')\n",
    "scores = cross_val_score(grid_search.best_estimator_, X_test, Y_test,cv=3,scoring='accuracy')\n",
    "print (scores.mean(),scores)\n",
    "\n",
    "# 对结果打分\n",
    "\n",
    "print(classification_report(Y_train, grid_search.best_estimator_.predict(X_train) ))\n",
    "print('test data')\n",
    "print(classification_report(Y_test, grid_search.best_estimator_.predict(X_test) ))\n",
    "\n",
    "model_file=MODEL_PATH+'model-rf.pkl'\n",
    "joblib.dump(grid_search.best_estimator_, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
